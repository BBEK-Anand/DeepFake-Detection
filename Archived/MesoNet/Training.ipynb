{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e165cb1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f3cca9af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%HTML\n",
    "<style>.container { width:100% !important; }</style>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6de523aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchsummary import summary\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms, datasets\n",
    "from torchmetrics.classification import BinaryAccuracy\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbdc4516",
   "metadata": {},
   "source": [
    "# Select model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ae6f97ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meso4_09\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 15, 240, 240]             420\n",
      "       BatchNorm2d-2         [-1, 15, 240, 240]              30\n",
      "         MaxPool2d-3         [-1, 15, 120, 120]               0\n",
      "            Conv2d-4         [-1, 15, 120, 120]           5,640\n",
      "       BatchNorm2d-5         [-1, 15, 120, 120]              30\n",
      "         MaxPool2d-6           [-1, 15, 60, 60]               0\n",
      "            Conv2d-7           [-1, 24, 60, 60]           9,024\n",
      "       BatchNorm2d-8           [-1, 24, 60, 60]              48\n",
      "         MaxPool2d-9           [-1, 24, 30, 30]               0\n",
      "           Conv2d-10           [-1, 24, 30, 30]          14,424\n",
      "      BatchNorm2d-11           [-1, 24, 30, 30]              48\n",
      "        MaxPool2d-12             [-1, 24, 7, 7]               0\n",
      "           Linear-13                   [-1, 15]          17,655\n",
      "          Dropout-14                   [-1, 15]               0\n",
      "           Linear-15                    [-1, 1]              16\n",
      "================================================================\n",
      "Total params: 47,335\n",
      "Trainable params: 47,335\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.66\n",
      "Forward/backward pass size (MB): 20.36\n",
      "Params size (MB): 0.18\n",
      "Estimated Total Size (MB): 21.20\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from Modeling import Meso4_09 as Curr_model\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") # Detect if GPU is available and use it\n",
    "model = Curr_model(num_classes=1).to(device)  # Move model to GPU if available\n",
    "model_name = str(model.__class__).split('.')[1][:-2]\n",
    "print(f\"{model_name}\")\n",
    "summary(model,model.input_shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9abce51",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8414f17d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define transformations for the dataset\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(model.input_shape[1:]),  # Resize images \n",
    "    transforms.ToTensor(),        # Convert images to tensor\n",
    "])\n",
    "\n",
    "# Create dataset and dataloader\n",
    "train_dataset = datasets.ImageFolder(root='../DataSet/real_vs_fake/real-vs-fake/train/', transform=transform)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=8, pin_memory=True)\n",
    "\n",
    "val_dataset = datasets.ImageFolder(root='../DataSet/real_vs_fake/real-vs-fake/valid/', transform=transform)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=8, pin_memory=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "69a166c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"criterion\": \"BCEWithLogitsLoss\",\n",
      "    \"optimizer\": \"Adam\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Configure the model for training , Set up criterion and optimizer\n",
    "criterion = nn.BCEWithLogitsLoss()  # Use BCEWithLogitsLoss for binary classification\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "config ={\n",
    "    \"criterion\": str(type(criterion)).split(\".\")[-1][:-2],\n",
    "    \"optimizer\": str(type(optimizer)).split(\".\")[-1][:-2]\n",
    "}\n",
    "print(json.dumps(config, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "84d3e398",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meso4_09_1 {\n",
      "   \"config\": {\n",
      "      \"criterion\": \"BCEWithLogitsLoss\",\n",
      "      \"optimizer\": \"Adam\"\n",
      "   },\n",
      "   \"last\": {\n",
      "      \"epoch\": 0,\n",
      "      \"train_accuracy\": 0,\n",
      "      \"train_loss\": 0,\n",
      "      \"val_accuracy\": 0,\n",
      "      \"val_loss\": 900\n",
      "   },\n",
      "   \"best\": {\n",
      "      \"epoch\": 0,\n",
      "      \"train_accuracy\": 0,\n",
      "      \"train_loss\": 0,\n",
      "      \"val_accuracy\": 0,\n",
      "      \"val_loss\": 900\n",
      "   }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "model_exists = False\n",
    "config_templete = {\n",
    "    \"config\":config,\n",
    "    \"last\":{\n",
    "        \"epoch\":0,\n",
    "        \"train_accuracy\":0,\n",
    "        \"train_loss\":0,\n",
    "        \"val_accuracy\":0,\n",
    "        \"val_loss\":900\n",
    "    },\n",
    "    \"best\":{\n",
    "        \"epoch\":0,\n",
    "        \"train_accuracy\":0,\n",
    "        \"train_loss\":0,\n",
    "        \"val_accuracy\":0,\n",
    "        \"val_loss\":900\n",
    "    }\n",
    "}\n",
    "all_models = json.load(open(\"config.json\"))\n",
    "if(0==len([i for i in all_models.keys() if model_name in i])):\n",
    "    model_name1 = model_name+\"_1\"\n",
    "    all_models[model_name1] = config_templete\n",
    "    pd.DataFrame(columns=[\"epoch\",\"train_accuracy\",\"train_loss\",\"val_accuracy\",\"val_loss\"]).to_csv(\"../History/\"+model_name1+\".csv\",index=False)\n",
    "    \n",
    "else:\n",
    "\n",
    "    dummy = [i for i in all_models if json.dumps(all_models[i][\"config\"])==json.dumps(config) and model_name in i]\n",
    "\n",
    "    if(len(dummy)==0):\n",
    "        model_name1 = model_name+\"_\"+str(max([i[:-2] for i in models]))\n",
    "        all_models[model_name1] = config_templete\n",
    "        pd.DataFrame(columns=[\"epoch\",\"train_accuracy\",\"train_loss\",\"val_accuracy\",\"val_loss\"]).to_csv(\"../History/\"+model_name1+\".csv\",index=False)\n",
    "\n",
    "    elif(len(dummy)==1):\n",
    "        model_name1 = dummy[0]\n",
    "        model_exists = True\n",
    "print(model_name1,json.dumps(all_models[model_name1],indent=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3551caf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load weights if available\n",
    "# Load best model for inference or further training\n",
    "best_model_path = \"../Models/\"+model_name1+\".pth\"\n",
    "if(model_exists):\n",
    "    model.load_state_dict(torch.load(best_model_path))\n",
    "    model.to(device)  # Ensure model is on the correct dev\n",
    "\n",
    "# update config at every epoch\n",
    "def update_config(ls,mode):\n",
    "    dct = dict(zip([\"epoch\",\"train_accuracy\",\"train_loss\",\"val_accuracy\",\"val_loss\"],ls))\n",
    "    if(mode==\"last\"):\n",
    "        pd.DataFrame([dct]).to_csv(\"../History/\"+model_name1+\".csv\", mode='a',header=False,index=False)\n",
    "    all_models[model_name1][mode]= dct\n",
    "    with open(\"config.json\", \"w\") as out_file:\n",
    "        out_file.write(json.dumps(all_models,indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8a05fd2",
   "metadata": {},
   "source": [
    "#  Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "82df7b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation function\n",
    "def validate(model, dataloader):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    accuracy_metric = BinaryAccuracy().to(device)\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in tqdm(dataloader, desc='Validating', leave=False):\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            labels = labels.float().unsqueeze(1)\n",
    "            \n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            running_loss += loss.item()\n",
    "            predictions = torch.sigmoid(outputs)\n",
    "            correct += accuracy_metric(predictions, labels.int()).item()\n",
    "            total += labels.size(0)\n",
    "    accuracy = correct / len(dataloader)\n",
    "    avg_loss = running_loss / len(dataloader)\n",
    "    return avg_loss, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3fa8e9fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs to train from     0   to   10\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 10\n",
    "start_epoch = all_models[model_name1][\"last\"][\"epoch\"]\n",
    "# num_epochs = start_epoch+num_epochs\n",
    "print(f\"Epochs to train from     {start_epoch}   to   {num_epochs}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abed1ce7",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5810d89e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10: 100%|█| 3125/3125 [27:41<00:00,  1.88it/s, accuracy=0.621, loss=0.6\n",
      "                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Train Loss: 0.6036, Train Accuracy: 0.62, Val Loss: 0.4444, Val Accuracy: 0.82\n",
      "Best model saved at epoch 1 with validation loss: 0.4444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10: 100%|█| 3125/3125 [27:23<00:00,  1.90it/s, accuracy=0.683, loss=0.5\n",
      "                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Train Loss: 0.4999, Train Accuracy: 0.68, Val Loss: 0.3282, Val Accuracy: 0.89\n",
      "Best model saved at epoch 2 with validation loss: 0.3282\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10: 100%|█| 3125/3125 [27:57<00:00,  1.86it/s, accuracy=0.706, loss=0.4\n",
      "                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Train Loss: 0.4544, Train Accuracy: 0.71, Val Loss: 0.2445, Val Accuracy: 0.91\n",
      "Best model saved at epoch 3 with validation loss: 0.2445\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/10: 100%|█| 3125/3125 [27:31<00:00,  1.89it/s, accuracy=0.715, loss=0.4\n",
      "                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Train Loss: 0.4315, Train Accuracy: 0.71, Val Loss: 0.2260, Val Accuracy: 0.93\n",
      "Best model saved at epoch 4 with validation loss: 0.2260\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/10: 100%|█| 3125/3125 [26:22<00:00,  1.97it/s, accuracy=0.726, loss=0.4\n",
      "                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, Train Loss: 0.4122, Train Accuracy: 0.73, Val Loss: 0.1795, Val Accuracy: 0.95\n",
      "Best model saved at epoch 5 with validation loss: 0.1795\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/10: 100%|█| 3125/3125 [26:57<00:00,  1.93it/s, accuracy=0.726, loss=0.4\n",
      "                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, Train Loss: 0.4029, Train Accuracy: 0.73, Val Loss: 0.1906, Val Accuracy: 0.94\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/10: 100%|█| 3125/3125 [27:18<00:00,  1.91it/s, accuracy=0.731, loss=0.3\n",
      "                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, Train Loss: 0.3964, Train Accuracy: 0.73, Val Loss: 0.1747, Val Accuracy: 0.95\n",
      "Best model saved at epoch 7 with validation loss: 0.1747\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/10: 100%|█| 3125/3125 [31:04<00:00,  1.68it/s, accuracy=0.734, loss=0.3\n",
      "                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, Train Loss: 0.3889, Train Accuracy: 0.73, Val Loss: 0.1363, Val Accuracy: 0.96\n",
      "Best model saved at epoch 8 with validation loss: 0.1363\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/10: 100%|█| 3125/3125 [30:21<00:00,  1.72it/s, accuracy=0.734, loss=0.3\n",
      "                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9, Train Loss: 0.3880, Train Accuracy: 0.73, Val Loss: 0.1637, Val Accuracy: 0.94\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|█| 3125/3125 [27:31<00:00,  1.89it/s, accuracy=0.736, loss=0.\n",
      "                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, Train Loss: 0.3832, Train Accuracy: 0.74, Val Loss: 0.1230, Val Accuracy: 0.96\n",
      "Best model saved at epoch 10 with validation loss: 0.1230\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "best_val_loss = float('inf') if all_models[model_name1][\"best\"][\"val_loss\"]==None else all_models[model_name1][\"best\"][\"val_loss\"]# Initialize best validation loss to infinity\n",
    "for epoch in range(start_epoch,num_epochs):  # number of epochs\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    running_accuracy = 0.0\n",
    "    accuracy_metric = BinaryAccuracy().to(device)\n",
    "    train_loader_tqdm = tqdm(train_loader, desc=f'Epoch {epoch+1}/{num_epochs}', leave=True)\n",
    "    for inputs, labels in train_loader_tqdm:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        labels = labels.float().unsqueeze(1)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        running_accuracy += accuracy_metric(torch.sigmoid(outputs), labels.int()).item()\n",
    "        train_loader_tqdm.set_postfix(loss=running_loss/len(train_loader_tqdm), accuracy=running_accuracy/len(train_loader_tqdm))\n",
    "    \n",
    "    train_loss = running_loss / len(train_loader)\n",
    "    train_accuracy = running_accuracy / len(train_loader)\n",
    "    val_loss, val_accuracy = validate(model, val_loader)\n",
    "    print(f'Epoch {epoch+1}, Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy:.2f}, Val Loss: {val_loss:.4f}, Val Accuracy: {val_accuracy:.2f}')\n",
    "    update_config(ls=[epoch+1,train_accuracy,train_loss,val_accuracy,val_loss], mode=\"last\")\n",
    "    # Save the best model if the validation loss has improved\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        torch.save(model.state_dict(), best_model_path)\n",
    "        update_config(ls=[epoch+1,train_accuracy,train_loss,val_accuracy,val_loss], mode=\"best\")\n",
    "        print(f\"Best model saved at epoch {epoch+1} with validation loss: {val_loss:.4f}\")\n",
    "\n",
    "        \n",
    "\n",
    "# song_path =\"../../../../../SYSTEM's/Byverse/Byverse  recovr/Mnx/Akshath - Nadaaniyan (Official Lyric Video)(M4A_128K).m4a\"\n",
    "# import IPython  \n",
    "# IPython.display.Audio(song_path,autoplay=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dd1acd9",
   "metadata": {},
   "source": [
    "song_path =\"D://SYSTEM's/Byverse/Byverse  recovr/Mnx/Akshath - Nadaaniyan (Official Lyric Video)(M4A_128K).m4a\"\n",
    "import IPython\n",
    "import time\n",
    "ply = IPython.display.Audio(song_path,autoplay=True)\n",
    "temp = 0\n",
    "while 1:\n",
    "    IPython.display.display(ply)\n",
    "    IPython.display.display(temp)\n",
    "    time.sleep(2*60+52)\n",
    "    temp += 2*60+52\n",
    "    IPython.display.clear_output(wait=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dc767a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3de1c7ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "float('inf') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10829802",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33741e15",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
