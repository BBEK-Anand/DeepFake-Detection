{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b96fb7ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container{width:100%}</styel>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%HTML\n",
    "<style>.container{width:100%}</styel>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0d31e0a",
   "metadata": {},
   "source": [
    "# step:- 1 | Set the default componets (accuracy, loss,optimizer) and default settings(traing data source, validation data source, training batch size and validation batch size)\n",
    "In my case it is deep Fake detection problem, so accuracy function is ***Binary Accuracy***, I have used `torchmetrics`  with the name `BinAcc`, but you can define your own inside the `Libs/accuracies.py` and can change the name of the function.\n",
    "\n",
    "Here loss function is ***Binary Cross Entropy***, I have used `torch.nn.BCE` inside `Libs/losses.py` with the name `BCE`.\n",
    "\n",
    "Here i take ***Adam*** optimizer ,i have defined inside `Libs/optimizers.py` with the name `OptAdam`.\n",
    "\n",
    "## saving the default configurations\n",
    "prepare a variable like\n",
    "```python\n",
    "dconfig = {\n",
    "    \"accuracy_loc\": \"BinAcc\",\n",
    "    \"loss_loc\": \"BCE\",\n",
    "    \"optimizer_loc\": \"OptAdam\",\n",
    "    \"train_data_src\": \"../DataSet/real_vs_fake/real_vs_fake/train/\",\n",
    "    \"valid_data_src\": \"../DataSet/real_vs_fake/real_vs_fake/valid/\",\n",
    "    \"train_batch_size\": 32,\n",
    "    \"valid_batch_size\": 24\n",
    "}\n",
    "```\n",
    "- **Note:** the values of `\"accuracy_loc\"`,`\"loss_loc\"` and `\"optimizer_loc\"` should be the as same as the names of functions defined inside `Libs/accuracies.py`, `Libs/losses.py` and `Libs/optimizers.py` respectively.\n",
    "- **Note:** the values of `train_data_src` and `\"valid_data_src\"` should be the correct file/folder path that should be proccessed by the `Dataset` classes which you have to design in `modeling.ipynb`\n",
    "And then use \n",
    "```python\n",
    "set_default_config(data=dconfig)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "23432513",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PyTorchLabFlow import set_default_config\n",
    "#set these for thwe first time, you can change this configuration latter also. it fixes the default configurations\n",
    "dconfig = {\n",
    "    \"accuracy_loc\": \"BinAcc\",\n",
    "    \"loss_loc\": \"BCE\",\n",
    "    \"optimizer_loc\": \"OptAdam\",\n",
    "    \"train_data_src\": \"../DataSet/real_vs_fake/real_vs_fake/train/\",\n",
    "    \"valid_data_src\": \"../DataSet/real_vs_fake/real_vs_fake/valid/\",\n",
    "    \"train_batch_size\": 32,\n",
    "    \"valid_batch_size\": 24\n",
    "}\n",
    "set_default_config(data=dconfig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9453da4",
   "metadata": {},
   "source": [
    "It will save these configurations inside `internal/default_Config.json` so that everytime you make a new experiment you dont have to assign those again and again, however you can change these configuration at the time of creating new experiment but make sure the avobe ***Note***\n",
    "\n",
    "## Now it is time to create a new jupyter file and name it as modelling. And follow the steps that i have covered in `modeling.ipynb`\n",
    "# After reading the steps we will come to this file again to train a experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c13dfa97",
   "metadata": {},
   "source": [
    "     .............................................................\n",
    "     .............................................................\n",
    "     .............................................................\n",
    "     ............................................................."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53444d3d",
   "metadata": {},
   "source": [
    "# Step:- 3 | Training and experiment\n",
    "Here you have to give each experiment a unique name so that you can access that experiment by their name\n",
    "call `train_new` with parameters `name`, `model_loc` and `dataset_loc`\n",
    "- **Note:** `name` should be unique for each experiment.\n",
    "- **Note:** `model_loc` should be the same string as the recently pasted model class's name.\n",
    "- **Note:** `model_loc` should be the same string as the recently pasted datset class's name.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5630fba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration file is saved at internal/Configs/exp01.json\n",
      "History will be saved at internal/Histories/exp01.csv\n",
      "Weights will be saved at internal/Weights/exp01.pth\n",
      "Data loaders are successfully created\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/2:   6%| | 201/3125 [00:15<04:23, 11.08it/s, accuracy=0.0327, loss=0.04"
     ]
    }
   ],
   "source": [
    "from PyTorchLabFlow import train_new\n",
    "P = train_new(name=\"exp01\",model_loc=\"testCNN\",dataset_loc=\"DS01\",prepare=True)\n",
    "P.train(num_epochs=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "049baa2d",
   "metadata": {},
   "source": [
    "# "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
